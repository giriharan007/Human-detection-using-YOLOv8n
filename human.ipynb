{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "```\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import pygame\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "model = YOLO('yolov8n.pt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "# Create a folder to save the extracted frames with humans```python\n",
    "if not os.path.exists(\"human_frames\"):\n",
    "    os.makedirs(\"human_frames\")\n",
    "\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "# Initialize the sound system (for human detection alert)```\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(r\"D:\\Projects\\Computer vision\\Video Human detection\\WhatsApp Audio 2024-09-17 at 16.13.55_9bd8c978.mp3\")  # Use any sound file like 'beep.mp3'\n",
    "\n",
    "# Initialize the video capture from the camera (use 0 for the default camera)```\n",
    "cap = cv2.VideoCapture(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2054371597.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ```python\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "```python\n",
    "cmd = str(input(\"Press 'on' to start the human detection or 'off' to stop it: \"))\n",
    "if cmd == \"on\":\n",
    "    frame_count = 0  # To count the frames\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Use the YOLO model to detect objects in the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        human_detected = False\n",
    "\n",
    "        # Draw bounding boxes only for human detections (Class 0 corresponds to \"person\")\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if int(box.cls[0]) == 0:  # Class 0 is for humans in the COCO dataset\n",
    "                    human_detected = True\n",
    "                    # Extract box coordinates\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    # Draw bounding box and label\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n",
    "                    cv2.putText(frame, 'Human', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # If a human is detected, play a sound and save the frame\n",
    "        if human_detected:\n",
    "            # Play sound (this will play the sound once per detection)\n",
    "            if frame_count == 1:\n",
    "                pygame.mixer.music.play()\n",
    "\n",
    "            # Save the frame in the \"human_frames\" folder\n",
    "            frame_path = f\"human_frames/frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frame_count += 1  # Increment the frame counter\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow('YOLOv8 Human Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pygame.mixer.quit()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
